{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c2ceb0-7ef2-464f-aea4-78f70def8483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import math\n",
    "import logging\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from evaluation.evaluation import eval_edge_prediction\n",
    "from model.tgn import TGN\n",
    "from utils.utils import EarlyStopMonitor, RandEdgeSampler, get_neighbor_finder\n",
    "from utils.data_processing import get_data, compute_time_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61ec36b4-42da-466a-a317-d826fa5bdc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x1038b84c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Seeds for Reproducability\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c5f0dae-7431-44c5-a878-b0ee12bc88f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = {\n",
    "    \"data\": \"wikipedia\",\n",
    "    \"bs\": 200,\n",
    "    \"prefix\": \"\",\n",
    "    \"n_degree\": 10,\n",
    "    \"n_head\": 2,\n",
    "    \"n_epoch\": 50,\n",
    "    \"n_layer\": 1,\n",
    "    \"lr\": 0.0001,\n",
    "    \"patience\": 5,\n",
    "    \"n_runs\": 1,\n",
    "    \"drop_out\": 0.1,\n",
    "    \"gpu\": 0,\n",
    "    \"node_dim\": 100,\n",
    "    \"time_dim\": 100,\n",
    "    \"backprop_every\": 1,\n",
    "    \"use_memory\": True,\n",
    "    \"embedding_module\": \"graph_attention\",\n",
    "    \"message_function\": \"identity\",\n",
    "    \"memory_updater\": \"gru\",\n",
    "    \"aggregator\": \"last\",\n",
    "    \"memory_update_at_end\": False,\n",
    "    \"message_dim\": 100,\n",
    "    \"memory_dim\": 172,\n",
    "    \"different_new_nodes\": False,\n",
    "    \"uniform\": False,\n",
    "    \"randomize_features\": False,\n",
    "    \"use_destination_embedding_in_message\": False,\n",
    "    \"use_source_embedding_in_message\": False,\n",
    "    \"dyrep\": False,\n",
    "}\n",
    "\n",
    "# Extract key parameters for easier use\n",
    "BATCH_SIZE = args[\"bs\"]\n",
    "NUM_NEIGHBORS = args[\"n_degree\"]\n",
    "NUM_EPOCH = args[\"n_epoch\"]\n",
    "NUM_HEADS = args[\"n_head\"]\n",
    "DROP_OUT = args[\"drop_out\"]\n",
    "GPU = args[\"gpu\"]\n",
    "DATA = args[\"data\"]\n",
    "NUM_LAYER = args[\"n_layer\"]\n",
    "LEARNING_RATE = args[\"lr\"]\n",
    "NODE_DIM = args[\"node_dim\"]\n",
    "TIME_DIM = args[\"time_dim\"]\n",
    "USE_MEMORY = args[\"use_memory\"]\n",
    "MESSAGE_DIM = args[\"message_dim\"]\n",
    "MEMORY_DIM = args[\"memory_dim\"]\n",
    "\n",
    "# Configure device\n",
    "device = torch.device(f\"cuda:{GPU}\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b673a124-bc72-440f-b9a7-6d025a114ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 157474 interactions, involving 9227 different nodes\n",
      "The training dataset has 81029 interactions, involving 6141 different nodes\n",
      "The validation dataset has 23621 interactions, involving 3256 different nodes\n",
      "The test dataset has 23621 interactions, involving 3564 different nodes\n",
      "The new node validation dataset has 12016 interactions, involving 2120 different nodes\n",
      "The new node test dataset has 11715 interactions, involving 2437 different nodes\n",
      "922 nodes were used for the inductive testing, i.e. are never seen during training\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "node_features, edge_features, full_data, train_data, val_data, test_data, new_node_val_data, new_node_test_data = get_data(\n",
    "    DATA,\n",
    "    different_new_nodes_between_val_and_test=args[\"different_new_nodes\"],\n",
    "    randomize_features=args[\"randomize_features\"],\n",
    ")\n",
    "\n",
    "# Initialize neighbor finders\n",
    "train_ngh_finder = get_neighbor_finder(train_data, args[\"uniform\"])\n",
    "full_ngh_finder = get_neighbor_finder(full_data, args[\"uniform\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57b661bf-855a-4138-94ca-68cda956c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TGN model\n",
    "tgn = TGN(\n",
    "    neighbor_finder=train_ngh_finder,\n",
    "    node_features=node_features,\n",
    "    edge_features=edge_features,\n",
    "    device=device,\n",
    "    n_layers=NUM_LAYER,\n",
    "    n_heads=NUM_HEADS,\n",
    "    dropout=DROP_OUT,\n",
    "    use_memory=USE_MEMORY,\n",
    "    message_dimension=MESSAGE_DIM,\n",
    "    memory_dimension=MEMORY_DIM,\n",
    "    memory_update_at_start=not args[\"memory_update_at_end\"],\n",
    "    embedding_module_type=args[\"embedding_module\"],\n",
    "    message_function=args[\"message_function\"],\n",
    "    aggregator_type=args[\"aggregator\"],\n",
    "    memory_updater_type=args[\"memory_updater\"],\n",
    "    n_neighbors=NUM_NEIGHBORS,\n",
    ")\n",
    "\n",
    "# Set up loss and optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(tgn.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Move model to device\n",
    "tgn = tgn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31e6d59d-407d-466a-a53d-e802bacdd43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathansneh/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/autograd/graph.py:825: UserWarning: Error detected in AddmmBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/Users/jonathansneh/.pyenv/versions/3.9.7/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/jonathansneh/.pyenv/versions/3.9.7/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/jonathansneh/.local/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/jonathansneh/.local/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/jonathansneh/.local/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/jonathansneh/.local/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/jonathansneh/.pyenv/versions/3.9.7/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/jonathansneh/.pyenv/versions/3.9.7/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/jonathansneh/.pyenv/versions/3.9.7/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/jonathansneh/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/jonathansneh/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/jonathansneh/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/jonathansneh/.local/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/jonathansneh/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/jonathansneh/.local/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/jonathansneh/.local/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/jonathansneh/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/jonathansneh/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/jonathansneh/.local/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/jonathansneh/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/jonathansneh/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/jonathansneh/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/c5/4sx9zv4s56sc2jwhq0rhlth80000gn/T/ipykernel_65800/2476213083.py\", line 23, in <module>\n",
      "    pos_prob, neg_prob = tgn.compute_edge_probabilities(\n",
      "  File \"/Users/jonathansneh/Desktop/Oxford/grl/tgn/model/tgn.py\", line 213, in compute_edge_probabilities\n",
      "    source_node_embedding, destination_node_embedding, negative_node_embedding = self.compute_temporal_embeddings(\n",
      "  File \"/Users/jonathansneh/Desktop/Oxford/grl/tgn/model/tgn.py\", line 166, in compute_temporal_embeddings\n",
      "    self.update_memory(positives, self.memory.messages)\n",
      "  File \"/Users/jonathansneh/Desktop/Oxford/grl/tgn/model/tgn.py\", line 235, in update_memory\n",
      "    self.memory_updater.update_memory(unique_nodes, unique_messages,\n",
      "  File \"/Users/jonathansneh/Desktop/Oxford/grl/tgn/modules/memory_updater.py\", line 28, in update_memory\n",
      "    updated_memory = self.memory_updater(unique_messages, memory)\n",
      "  File \"/Users/jonathansneh/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/jonathansneh/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/jonathansneh/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/nn/modules/rnn.py\", line 1812, in forward\n",
      "    ret = _VF.gru_cell(\n",
      " (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:115.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [688, 516]], which is output 0 of AsStridedBackward0, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m neg_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(size, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pos_prob\u001b[38;5;241m.\u001b[39msqueeze(), pos_label) \u001b[38;5;241m+\u001b[39m criterion(neg_prob\u001b[38;5;241m.\u001b[39msqueeze(), neg_label)\n\u001b[0;32m---> 31\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     33\u001b[0m epoch_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [688, 516]], which is output 0 of AsStridedBackward0, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    start_time = time.time()\n",
    "    print(f\"Starting epoch {epoch}\")\n",
    "    \n",
    "    # Initialize memory\n",
    "    if USE_MEMORY:\n",
    "        tgn.memory.__init_memory__()\n",
    "    \n",
    "    tgn.set_neighbor_finder(train_ngh_finder)\n",
    "\n",
    "    epoch_loss = []\n",
    "    for batch_idx in range(0, len(train_data.sources), BATCH_SIZE):\n",
    "        optimizer.zero_grad()\n",
    "        sources = train_data.sources[batch_idx: batch_idx + BATCH_SIZE]\n",
    "        destinations = train_data.destinations[batch_idx: batch_idx + BATCH_SIZE]\n",
    "        timestamps = train_data.timestamps[batch_idx: batch_idx + BATCH_SIZE]\n",
    "        edge_idxs = train_data.edge_idxs[batch_idx: batch_idx + BATCH_SIZE]\n",
    "        \n",
    "        size = len(sources)\n",
    "        _, negatives = RandEdgeSampler(sources, destinations).sample(size)\n",
    "\n",
    "        pos_prob, neg_prob = tgn.compute_edge_probabilities(\n",
    "            sources, destinations, negatives, timestamps, edge_idxs, NUM_NEIGHBORS\n",
    "        )\n",
    "\n",
    "        pos_label = torch.ones(size, dtype=torch.float, device=device)\n",
    "        neg_label = torch.zeros(size, dtype=torch.float, device=device)\n",
    "\n",
    "        loss = criterion(pos_prob.squeeze(), pos_label) + criterion(neg_prob.squeeze(), neg_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    \n",
    "    print(f\"Epoch {epoch} completed. Loss: {np.mean(epoch_loss):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9d97b94-6a38-4185-84a9-2061250e4b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_compiled_call_impl', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', '_wrapped_call_impl', 'add_module', 'affinity_score', 'apply', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'compute_edge_probabilities', 'compute_temporal_embeddings', 'cpu', 'cuda', 'device', 'double', 'dump_patches', 'dyrep', 'edge_raw_features', 'embedding_dimension', 'embedding_module', 'embedding_module_type', 'eval', 'extra_repr', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_raw_messages', 'get_submodule', 'get_updated_memory', 'half', 'ipu', 'load_state_dict', 'logger', 'mean_time_shift_dst', 'mean_time_shift_src', 'memory', 'modules', 'mtia', 'n_edge_features', 'n_layers', 'n_neighbors', 'n_node_features', 'n_nodes', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'neighbor_finder', 'node_raw_features', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'set_extra_state', 'set_neighbor_finder', 'set_submodule', 'share_memory', 'state_dict', 'std_time_shift_dst', 'std_time_shift_src', 'time_encoder', 'to', 'to_empty', 'train', 'training', 'type', 'update_memory', 'use_destination_embedding_in_message', 'use_memory', 'use_source_embedding_in_message', 'xpu', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "print(dir(tgn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae72ee1-7c4b-4c48-bd03-79bcd72787af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
