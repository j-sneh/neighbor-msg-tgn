{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1c2ceb0-7ef2-464f-aea4-78f70def8483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from evaluation.evaluation import eval_edge_prediction\n",
    "from model.tgn import TGN\n",
    "from utils.utils import EarlyStopMonitor, RandEdgeSampler, get_neighbor_finder\n",
    "from utils.data_processing import get_data, compute_time_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61ec36b4-42da-466a-a317-d826fa5bdc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x31561c8b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Seeds for Reproducability\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c5f0dae-7431-44c5-a878-b0ee12bc88f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = {\n",
    "    \"data\": \"wikipedia\",\n",
    "    \"bs\": 200,\n",
    "    \"prefix\": \"\",\n",
    "    \"n_degree\": 10,\n",
    "    \"n_head\": 2,\n",
    "    \"n_epoch\": 50,\n",
    "    \"n_layer\": 1,\n",
    "    \"lr\": 0.0001,\n",
    "    \"patience\": 5,\n",
    "    \"n_runs\": 1,\n",
    "    \"drop_out\": 0.1,\n",
    "    \"gpu\": 0,\n",
    "    \"node_dim\": 100,\n",
    "    \"time_dim\": 100,\n",
    "    \"backprop_every\": 1,\n",
    "    \"use_memory\": True,\n",
    "    \"embedding_module\": \"graph_attention\",\n",
    "    \"message_function\": \"identity\",\n",
    "    \"memory_updater\": \"gru\",\n",
    "    \"aggregator\": \"last\",\n",
    "    \"memory_update_at_end\": False,\n",
    "    \"message_dim\": 100,\n",
    "    \"memory_dim\": 172,\n",
    "    \"different_new_nodes\": False,\n",
    "    \"uniform\": False,\n",
    "    \"randomize_features\": False,\n",
    "    \"use_destination_embedding_in_message\": False,\n",
    "    \"use_source_embedding_in_message\": False,\n",
    "    \"dyrep\": False,\n",
    "}\n",
    "\n",
    "# Extract key parameters for easier use\n",
    "BATCH_SIZE = args[\"bs\"]\n",
    "NUM_NEIGHBORS = args[\"n_degree\"]\n",
    "NUM_EPOCH = args[\"n_epoch\"]\n",
    "NUM_HEADS = args[\"n_head\"]\n",
    "DROP_OUT = args[\"drop_out\"]\n",
    "GPU = args[\"gpu\"]\n",
    "DATA = args[\"data\"]\n",
    "NUM_LAYER = args[\"n_layer\"]\n",
    "LEARNING_RATE = args[\"lr\"]\n",
    "NODE_DIM = args[\"node_dim\"]\n",
    "TIME_DIM = args[\"time_dim\"]\n",
    "USE_MEMORY = args[\"use_memory\"]\n",
    "MESSAGE_DIM = args[\"message_dim\"]\n",
    "MEMORY_DIM = args[\"memory_dim\"]\n",
    "\n",
    "# Configure device\n",
    "device = torch.device(f\"cuda:{GPU}\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4693f09b-6157-4b9c-a647-153f463fa7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rand_sampler = RandEdgeSampler(train_data.sources, train_data.destinations)\n",
    "val_rand_sampler = RandEdgeSampler(full_data.sources, full_data.destinations, seed=0)\n",
    "nn_val_rand_sampler = RandEdgeSampler(new_node_val_data.sources, new_node_val_data.destinations,\n",
    "                                      seed=1)\n",
    "test_rand_sampler = RandEdgeSampler(full_data.sources, full_data.destinations, seed=2)\n",
    "nn_test_rand_sampler = RandEdgeSampler(new_node_test_data.sources,\n",
    "                                       new_node_test_data.destinations,\n",
    "                                       seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b673a124-bc72-440f-b9a7-6d025a114ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 157474 interactions, involving 9227 different nodes\n",
      "The training dataset has 81029 interactions, involving 6141 different nodes\n",
      "The validation dataset has 23621 interactions, involving 3256 different nodes\n",
      "The test dataset has 23621 interactions, involving 3564 different nodes\n",
      "The new node validation dataset has 12016 interactions, involving 2120 different nodes\n",
      "The new node test dataset has 11715 interactions, involving 2437 different nodes\n",
      "922 nodes were used for the inductive testing, i.e. are never seen during training\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "node_features, edge_features, full_data, train_data, val_data, test_data, new_node_val_data, new_node_test_data = get_data(\n",
    "    DATA,\n",
    "    different_new_nodes_between_val_and_test=args[\"different_new_nodes\"],\n",
    "    randomize_features=args[\"randomize_features\"],\n",
    ")\n",
    "\n",
    "# Initialize neighbor finders\n",
    "train_ngh_finder = get_neighbor_finder(train_data, args[\"uniform\"])\n",
    "full_ngh_finder = get_neighbor_finder(full_data, args[\"uniform\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57b661bf-855a-4138-94ca-68cda956c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TGN model\n",
    "tgn = TGN(\n",
    "    neighbor_finder=train_ngh_finder,\n",
    "    node_features=node_features,\n",
    "    edge_features=edge_features,\n",
    "    device=device,\n",
    "    n_layers=NUM_LAYER,\n",
    "    n_heads=NUM_HEADS,\n",
    "    dropout=DROP_OUT,\n",
    "    use_memory=USE_MEMORY,\n",
    "    message_dimension=MESSAGE_DIM,\n",
    "    memory_dimension=MEMORY_DIM,\n",
    "    memory_update_at_start=not args[\"memory_update_at_end\"],\n",
    "    embedding_module_type=args[\"embedding_module\"],\n",
    "    message_function=args[\"message_function\"],\n",
    "    aggregator_type=args[\"aggregator\"],\n",
    "    memory_updater_type=args[\"memory_updater\"],\n",
    "    n_neighbors=NUM_NEIGHBORS,\n",
    ")\n",
    "\n",
    "# Set up loss and optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(tgn.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Move model to device\n",
    "tgn = tgn.to(device)\n",
    "\n",
    "num_batch = math.ceil(len(train_data.sources) / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31e6d59d-407d-466a-a53d-e802bacdd43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Trying to update memory to time in the past",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m USE_MEMORY:\n\u001b[1;32m     60\u001b[0m     train_memory_backup \u001b[38;5;241m=\u001b[39m tgn\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mbackup_memory()\n\u001b[0;32m---> 61\u001b[0m val_ap, val_auc \u001b[38;5;241m=\u001b[39m \u001b[43meval_edge_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mnegative_edge_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_rand_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_NEIGHBORS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m USE_MEMORY:\n\u001b[1;32m     66\u001b[0m     val_memory_backup \u001b[38;5;241m=\u001b[39m tgn\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mbackup_memory()\n",
      "File \u001b[0;32m~/Desktop/Oxford/grl/tgn/evaluation/evaluation.py:36\u001b[0m, in \u001b[0;36meval_edge_prediction\u001b[0;34m(model, negative_edge_sampler, data, n_neighbors, batch_size)\u001b[0m\n\u001b[1;32m     33\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sources_batch)\n\u001b[1;32m     34\u001b[0m _, negative_samples \u001b[38;5;241m=\u001b[39m negative_edge_sampler\u001b[38;5;241m.\u001b[39msample(size)\n\u001b[0;32m---> 36\u001b[0m pos_prob, neg_prob \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_edge_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43msources_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestinations_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mnegative_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamps_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43medge_idxs_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m pred_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([(pos_prob)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), (neg_prob)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()])\n\u001b[1;32m     41\u001b[0m true_label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([np\u001b[38;5;241m.\u001b[39mones(size), np\u001b[38;5;241m.\u001b[39mzeros(size)])\n",
      "File \u001b[0;32m~/Desktop/Oxford/grl/tgn/model/tgn.py:210\u001b[0m, in \u001b[0;36mTGN.compute_edge_probabilities\u001b[0;34m(self, source_nodes, destination_nodes, negative_nodes, edge_times, edge_idxs, n_neighbors)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03mCompute probabilities for edges between sources and destination and between sources and\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03mnegatives by first computing temporal embeddings using the TGN encoder and then feeding them\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m:return: Probabilities for both the positive and negative edges\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    209\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(source_nodes)\n\u001b[0;32m--> 210\u001b[0m source_node_embedding, destination_node_embedding, negative_node_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_temporal_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m  \u001b[49m\u001b[43msource_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_idxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maffinity_score(torch\u001b[38;5;241m.\u001b[39mcat([source_node_embedding, source_node_embedding], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    214\u001b[0m                             torch\u001b[38;5;241m.\u001b[39mcat([destination_node_embedding,\n\u001b[1;32m    215\u001b[0m                                        negative_node_embedding]))\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    216\u001b[0m pos_score \u001b[38;5;241m=\u001b[39m score[:n_samples]\n",
      "File \u001b[0;32m~/Desktop/Oxford/grl/tgn/model/tgn.py:126\u001b[0m, in \u001b[0;36mTGN.compute_temporal_embeddings\u001b[0;34m(self, source_nodes, destination_nodes, negative_nodes, edge_times, edge_idxs, n_neighbors)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_memory:\n\u001b[1;32m    124\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory_update_at_start:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# Update memory for all nodes with messages stored in previous batches\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m     memory, last_update \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_updated_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_nodes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mget_memory(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_nodes)))\n",
      "File \u001b[0;32m~/Desktop/Oxford/grl/tgn/model/tgn.py:245\u001b[0m, in \u001b[0;36mTGN.get_updated_memory\u001b[0;34m(self, nodes, messages)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_nodes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    243\u001b[0m   unique_messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage_function\u001b[38;5;241m.\u001b[39mcompute_message(unique_messages)\n\u001b[0;32m--> 245\u001b[0m updated_memory, updated_last_update \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory_updater\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_updated_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m                                                                             \u001b[49m\u001b[43munique_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m                                                                             \u001b[49m\u001b[43mtimestamps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_timestamps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m updated_memory, updated_last_update\n",
      "File \u001b[0;32m~/Desktop/Oxford/grl/tgn/modules/memory_updater.py:36\u001b[0m, in \u001b[0;36mSequenceMemoryUpdater.get_updated_memory\u001b[0;34m(self, unique_node_ids, unique_messages, timestamps)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_node_ids) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     34\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclone(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mlast_update\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mget_last_update(unique_node_ids) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m timestamps)\u001b[38;5;241m.\u001b[39mall()\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m     37\u001b[0m                                                                                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate memory to time in the past\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m updated_memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m     40\u001b[0m updated_memory[unique_node_ids] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory_updater(unique_messages, updated_memory[unique_node_ids])\n",
      "\u001b[0;31mAssertionError\u001b[0m: Trying to update memory to time in the past"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "new_nodes_val_aps = []\n",
    "val_aps = []\n",
    "epoch_times = []\n",
    "total_epoch_times = []\n",
    "train_losses = []\n",
    "\n",
    "early_stopper = EarlyStopMonitor(max_round=args[\"patience\"])\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    start_epoch = time.time()\n",
    "    \n",
    "    # Initialize memory\n",
    "    if USE_MEMORY:\n",
    "        tgn.memory.__init_memory__()\n",
    "    \n",
    "    tgn.set_neighbor_finder(train_ngh_finder)\n",
    "    m_loss = []\n",
    "    print(f\"Starting epoch {epoch}\")\n",
    "    for k in range(0, num_batch, args[\"backprop_every\"]):\n",
    "        loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        for j in range(args[\"backprop_every\"]):\n",
    "            batch_idx = k + j\n",
    "\n",
    "            if batch_idx >= num_batch:\n",
    "                continue\n",
    "\n",
    "            start_idx = batch_idx * BATCH_SIZE\n",
    "            end_idx = min(len(train_data.sources), start_idx + BATCH_SIZE)\n",
    "            \n",
    "            sources_batch = train_data.sources[start_idx:end_idx]\n",
    "            destinations_batch = train_data.destinations[start_idx:end_idx]\n",
    "            edge_idxs_batch = train_data.edge_idxs[start_idx: end_idx]\n",
    "            timestamps_batch = train_data.timestamps[start_idx:end_idx]\n",
    "\n",
    "            size = len(sources_batch)\n",
    "            _, negatives_batch = train_rand_sampler.sample(size)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pos_label = torch.ones(size, dtype=torch.float, device=device)\n",
    "                neg_label = torch.zeros(size, dtype=torch.float, device=device)\n",
    "            tgn = tgn.train()\n",
    "            pos_prob, neg_prob = tgn.compute_edge_probabilities(sources_batch, destinations_batch, negatives_batch,\n",
    "                                                            timestamps_batch, edge_idxs_batch, NUM_NEIGHBORS)\n",
    "            loss += criterion(pos_prob.squeeze(), pos_label) + criterion(neg_prob.squeeze(), neg_label)\n",
    "        loss /= args[\"backprop_every\"]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        m_loss.append(loss.item())\n",
    "\n",
    "        if USE_MEMORY:\n",
    "            tgn.memory.detach_memory()\n",
    "\n",
    "        epoch_time = time.time() - start_epoch\n",
    "        epoch_times.append(epoch_time)\n",
    "\n",
    "        ### Validation\n",
    "        tgn.set_neighbor_finder(full_ngh_finder)\n",
    "        if USE_MEMORY:\n",
    "            train_memory_backup = tgn.memory.backup_memory()\n",
    "        val_ap, val_auc = eval_edge_prediction(model=tgn,\n",
    "                                                negative_edge_sampler=val_rand_sampler,\n",
    "                                                data=val_data,\n",
    "                                                n_neighbors=NUM_NEIGHBORS)\n",
    "        if USE_MEMORY:\n",
    "            val_memory_backup = tgn.memory.backup_memory()\n",
    "            tgn.memory.restore_memory(train_memory_backup)\n",
    "        nn_val_ap, nn_val_auc = eval_edge_prediction(model=tgn,\n",
    "                                    negative_edge_sampler=val_rand_sampler,\n",
    "                                    data=new_node_val_data,\n",
    "                                    n_neighbors=NUM_NEIGHBORS)\n",
    "        if USE_MEMORY:\n",
    "            tgn.memory.restore_memory(val_memory_backup)\n",
    "\n",
    "        new_nodes_val_aps.append(nn_val_ap)\n",
    "        val_aps.append(val_ap)\n",
    "        train_losses.append(np.mean(m_loss))\n",
    "            \n",
    "        total_epoch_time = time.time() - start_epoch\n",
    "        total_epoch_times.append(total_epoch_time)\n",
    "    \n",
    "    print(f\"Epoch {epoch} completed in f{total_epoch_time:.2f}s Loss: {np.mean(epoch_loss):.4f}\")\n",
    "    print(f\"val auc: {val_auc}, new node val auc: {nn_val_auc}\")\n",
    "    print(f\"val ap: {val_ap}, new node val ap: {nn_val_ap}\")\n",
    "\n",
    "    if early_stopper.early_stop_check(val_ap):\n",
    "        print('No improvement over {} epochs, stop training'.format(early_stopper.max_round))\n",
    "        print(f'Loading the best model at epoch {early_stopper.best_epoch}')\n",
    "        best_model_path = get_checkpoint_path(early_stopper.best_epoch)\n",
    "        tgn.load_state_dict(torch.load(best_model_path))\n",
    "        print(f'Loaded the best model at epoch {early_stopper.best_epoch} for inference')\n",
    "        tgn.eval()\n",
    "        break\n",
    "    else:\n",
    "        torch.save(tgn.state_dict(), get_checkpoint_path(epoch))\n",
    "\n",
    "    if USE_MEMORY:\n",
    "        val_memory_backup = tgn.memory.backup_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eae72ee1-7c4b-4c48-bd03-79bcd72787af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jonathansneh/.pyenv/versions/3.9.7/bin/python\n",
      "/Users/jonathansneh/.pyenv/versions/3.9.7/bin/jupyter-notebook\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!which jupyter-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba66c53-f0f4-48ad-aa50-2655a021171b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
